\section{Lineare Räume}
\subsection{Algebraische Strukturen}
Bezeichnet $M\not=\emptyset$ eine Menge und $F(M)$ die Menge aller Selbstabbildungen auf $M$, so kann die Komposition $\circ$ als Abbildung $\circ : F(M)\times F(M) \rightarrow F(M)$ interpretiert werden - man spricht von einer \underline{Verknüpfung}.
\subsubsection{Definition (Gruppe)}
Eine \underline{Gruppe} $(G,\cdot)$ ist eine nichtleer Menge $\mathbb{G}$ mit einer Veknüpfung $\cdot:\mathbb{G}\times\mathbb{G} \rightarrow \mathbb{G}$ mit den Eigenschaften:
$(G_1) \cdot$ ist \underline{Assoziativ}, d.h. $a\cdot(b\cdot c)=(a\cdot b)\cdot c$ für $a,b,c\in \mathbb{G}$\\
$(G_2)$ es existiert ein \underline{neutrales Element} $e\in\mathbb{G}$ mit $a\cdot e=a=e\cdot a$ für $a\in\mathbb{G}$\\
$(G_3)$ zu jedem $a\in\mathbb{G}$ existiert ein \underline{inverses Element} $a^{-1}\in \mathbb{G}$ mit $a\cdot a^{-1}=a^{-1}\cdot a=e$ für $a\in \mathbb{G}$\\
Bei einer kommutativen oder Abel'scher Gruppe gilt ferner $(G_4) a\cdot b=b\cdot a$ für alle $a,b\in \mathbb{G}$.  Für eine \underline{Halbgruppe} müssen nur $(G_1)$ und $(G_2)$ gelten.
\subsubsection{Bemerkung}
\renewcommand{\labelenumi}{(\arabic{enumi})}
\begin{enumerate}
\item Das neutrale Element $e\in\mathbb{G}$ ist eindeutig: In der Tat, bezeichnen $e_1,e_2\in\mathbb{G}$ zwei neutrale Elemente, so folgt nach $(G_2)$ ist: $e_2=e_1\cdot e_2$ und $e_1\cdot e_2=e_1$, also $e_1=e_2$
\item Zu gegebenem $a\in\mathbb{G}$ ist auch das inverse Element $a^{-1}\in\mathbb{G}$ eindeutig.  Für inverse Element $a_1^{-1},a_2^{-1}$ von $a$ gilt nämlich
\[a_1^{-1}\stackrel{(G_2)}{=}a_1^{-1}\cdot e\stackrel{(G_3)}{=}a_1^{-1}\cdot(a\cdot a_2^{-1})\stackrel{(G_1)}{=}(a_1^{-1}\cdot a)\cdot a_2^{-1}\stackrel{(G_3)}{=}e\cdot a_2^{-1}\stackrel{(G_2)}{=}a_2^{-1}\]
\item Entsprechend $e=e^{-1}$, $a=(a^{-1})^{-1}$
\end{enumerate}
\subsubsection{Bemerkung (Potenzen)}
Die Potenzen $a^n\in \mathbb{G}$ eines $a\in\mathbb{G}$ (G ist eine multiplikative Halbgruppe) sind rekursiv erklärt durch $a^0:=e, a^{n+1}:=a\cdot a^n$ für alle $n\in\mathbb{N}_0$.  In einer Gruppe setzen wir $a^n:=(a^{-n})^{-1}$ für $n<0$.
\subsubsection{Beispiel}
\begin{enumerate}
\item $(\mathbb{Z},+)$ ist eine kommutative additive Gruppe mit neutralen Element $0$ und dem zu $a\in\mathbb{Z}$ inverses Element $-a$.  Dagegen ist $(\mathbb{Z},\cdot )$ keine Gruppe, denn das multiplikative Inverses lässt sich innerhalb von $\mathbb{Z}$ nicht erklären.  Ebenso ist $(\mathbb{N},+)$ keine (additive) Gruppe.
\item Es sei $\mathbb{K}\in \{\mathbb{Q},\mathbb{R},\mathbb{C}\}$. Dann ist $(\mathbb{K},+)$ eine kommutative additive Gruppe mit neutralem Element $0$ und $-a$ als zu $a$ Inversen.  Auch $(\mathbb{K}\setminus \{0\},\cdot )$ ist eine kommutative multiplikative Gruppe mit neutralem Element $1$ und dem zu $a$ inversen Element $\frac{1}{a}$.
\item Mit $\mathbb{K}\in\{\mathbb{Z},\mathbb{Q},\mathbb{C}\}$ bilden die Matrizen $(\mathbb{K}^{m\times n},+)$ eine kommutative additive Gruppe mit neutralem Element $0$ und den Inversen $-A$ zu $A$.  Die quadratischen reellen rationalen oder komplexen Matrizen $(\mathbb{K}^{m\times n}\setminus \{0\},\cdot)$ bilden keine Gruppe, da etwa diag$(1,0)\not= 0$ kein Inverses besitzt.
\end{enumerate}
\addtocounter{subsubsection}{1}
\subsubsection{Beispiel (modulo)}
Es sei $p\geq 2$ eine ganze Zahl und $\mathbb{Z}_p:=\{0,\cdots ,p-1\}$.  Für beliebige $a,b\in\mathbb{Z}$ gibt es vermöge der Division mit Rest eindeutige $m\in\mathbb{Z}$ und $k\in\mathbb{Z}_p$ mit $a+b=mp+k$ wir schreiben dann $k=a+b$ mod $p$ oder $k=:a+_p b$.  Dann ist $(\mathbb{Z}_p,+_p)$ eine kommutative Gruppe mit dem neutralem Element $0$.
\subsubsection{Beispiel (symmetrische Gruppe)}
Es sei $M$ eine nichtleere Menge und $S(M)$ bezeichnet alle bijektiven Selbstabbildungen $f:M\rightarrow M$.  Dann ist die \underline{symmetrischen Gruppe} $(S(M),\circ )$ eine i.A. nicht-kommutative Gruppe mit id$_m$ als neutralem Element und $f^{-1}:M\rightarrow M$ als inversen Element zu $f$.  Im Fall $M=\{1,\cdots ,n\}$ schreiben wir $S_n:=S(\{1,\cdots ,n\})$.  Die Menge aller nicht-notwendig bijektiven Selbstabbildungen $F(M)$ ist dagegen eine Halbgruppe bezüglich $\circ$.
\subsubsection{Korollar (Rechnen in Gruppen)}
Für alle $a,b,c\in\mathbb{G}$ gilt $(a\cdot b)^{-1}=b^{-1}\cdot a^{-1}$, wie auch $a\cdot b=a\cdot c\Rightarrow b=c,a\cdot b=e\Rightarrow a=b^{-1}$.\\
Beweis:\\
Es seien $a,b,c\in\mathbb{G}$.  Wir zeigen zunächst, dass $b^{-1}\cdot a^{-1}$ das inverse Element von $a\cdot b$ ist.  Dazu 
\[(b^{-1}\cdot a^{-1})\cdot(a\cdot b)\stackrel{(G_1)}{=} b^{-1}\cdot(a^{-1}\cdot(a\cdot b\cdot))\stackrel{(G_1)}{=}b^{-1}\cdot((a^{-1}\cdot a)\cdot b)\stackrel{(G_3)}{=} b^{-1}\cdot(e\cdot b)\stackrel{(G_2)}{=}b^{-1}\cdot b\stackrel{(G_3)}{=}e\]
und entsprechend $(a\cdot b)\cdot(b^{-1}\cdot a^{-1})=e$.  Die erste Implikation ergibt sich nach Voraussetzung durch 
\[b\stackrel{(G_2)}{=}e\cdot b\stackrel{(G_3)}{=}(a^{-1}\cdot a)\cdot b\stackrel{(G_1)}{=}a^{-1}+(a\cdot b)=a^{-1}\cdot(a\cdot c)\stackrel{(G_1)}{=}(a^{-1}\cdot a)\cdot c\stackrel{(G_3)}{=}e\cdot c\stackrel{(G_2)}{=}c\]
Die verbleibende Implikation sei den Leser überlassen.
\subsubsection{Definition (Körper)}
Ein \underline{Körper} $(\mathbb{K},+,\cdot )$ ist eine Menge $\mathbb{K}$ mit mindestens zwei Elementen versehen.\\Mit den \underline{arithmetischen Operationen} $+: \mathbb{K}\times\mathbb{K}\rightarrow \mathbb{K}$ (\underline{Addition}) und $\cdot : \mathbb{K}\times\mathbb{K}\rightarrow \mathbb{K}$(\underline{Multiplikation}).\\
$(\mathbb{K}_1) (\mathbb{K},+)$ ist eine kommutative Gruppe mit neutralem Element $0$ und den zu $\alpha\in\mathbb{K}$ inversen Element $-\alpha$, d.h. für alle $\alpha ,\beta ,\gamma\in\mathbb{K}$ gilt:\\
\begin{align*}
(\mathbb{K}_1^1) & \alpha +(\beta + \gamma )= (\alpha + \beta)+\gamma \\
(\mathbb{K}_1^2) & \alpha + 0 = 0 + \alpha = \alpha \\
(\mathbb{K}_1^3) & \alpha \cdot -\alpha = -\alpha \cdot \alpha = 0 \\
(\mathbb{K}_1^4) & \alpha + \beta = \beta + \alpha
\end{align*}
($\mathbb{K}_2$) ($\mathbb{K}\setminus \{0\},\cdot$) ist eine kommutative Gruppe mit neutralem Element $1$ und zu $\alpha\in \mathbb{K}$ Inversem $\frac{1}{\alpha}$, d.h. es gilt für $\alpha ,\beta ,\gamma \in \mathbb{K}\setminus \{0\}$.
\begin{align*}
(\mathbb{K}_2^1) & \alpha \cdot (\beta \cdot \gamma ) = (\alpha \cdot \beta )\cdot \gamma\\
(\mathbb{K}_2^2) & \alpha \cdot 1 = 1\cdot\alpha = \alpha \\
(\mathbb{K}_2^3) & \alpha \cdot \frac{1}{\alpha} = \frac{1}{\alpha}\cdot\alpha = 1 \\
(\mathbb{K}_2^4) & \alpha \cdot \beta = \beta \cdot \alpha
\end{align*}
($\mathbb{K}_3$) es gelten die Distributivgesetze $\alpha (\beta +\gamma )=\alpha \cdot \beta + \alpha \cdot \gamma$, $(\alpha + \beta ) \cdot \gamma = \alpha\gamma + \beta\gamma$ für alle $\alpha ,\beta ,\gamma \in \mathbb{K}$.  Üblich $\alpha\beta :=\alpha \cdot \gamma$.  Subtraktion als $\alpha - \beta := \alpha + (-\beta )$.  Division $\frac{\alpha}{\beta} := \alpha \cdot \frac{1}{\beta}$.
\subsubsection{Beispiel}
$\mathbb{Q},\mathbb{R},\mathbb{C}$ sind Körper bzgl. $+,\cdot$
\subsubsection{Beispiel (Restklassenkörper modulo $p$)}
Mit einer gegebenen Primzahl $p\in\mathbb{N}$ definieren wir die Mengen $\mathbb{Z}_p := \{0,\cdots ,p\}$.  Dann gibt für beliebige $\alpha ,\beta \in \mathbb{Z}_p$ eindeutige Zahlen $m,n\in\mathbb{Z}$ und $k,l\in\mathbb{Z}_p$ derart, dass 
\[\alpha + \beta = m\cdot p+k\]
\[\alpha\cdot\beta = np+l \text{ Divison mit Rest.}\]
\[\text{Addition: }\alpha+_p \beta := k\]
\[\text{Multiplikation: }\alpha \cdot_p \beta := l\text{ (2.1a)}\]
$(\mathbb{Z}_p,+_p,\cdot_p)$ ist Körper, der sogenannten Restklassenkörper modulo $p$.
\[\mathbb{Z}_2: \begin{array}{c|cc}+_2 & 0 & 1\\ \hline\\ 0 & 0 & 1 \\ 1 & 1 & 0\end{array} \]
\[\begin{array}{c|cc}\cdot_2 & 0 & 1\\ \hline \\ 0 & 0 & 0 \\ 1 & 0 & 1\end{array} \]
\[\mathbb{Z}_3: \begin{array}{c|ccc}+_3 & 0 & 1 & 2\\ \hline \\ 0 & 0 & 1 & 2\\ 1 & 1 & 2 & 0\\2 & 2 & 0 & 1\end{array} \]
\[\begin{array}{c|ccc}\cdot_3 & 0 & 1 & 2\\ \hline \\ 0 & 0 & 0 & 0\\ 1 & 0 & 1 & 2\\2 & 0 & 2 & 1\end{array} \]
\subsubsection{Korollar}
Ist ($\mathbb{K},+,\cdot $) ein Körper, so gilt für alle $\alpha ,\beta ,\gamma \in \mathbb{K}$, dass
\begin{align*}
0\cdot \alpha &= \alpha \cdot 0 = 0, & \beta\cdot (-\alpha ) = -(\beta \cdot \alpha ) = (-\beta )\cdot \alpha &(2.1b)\\
(-1)\cdot \alpha &= -\alpha , & (-\alpha )\cdot (-\beta ) = \alpha\cdot\beta &(2.1c)
\end{align*}
Und ferner die Implikation $\alpha\cdot\beta = 0 \rightarrow \alpha = 0$ oder $\beta = 0$.
\subsubsection{Bemerkung}
Es gilt $1\not=0$, da die Annahme $1=0$ folgenden Widerspruch impliziert: Da $\mathbb{K}$ mindestens $2$ Elemente enthält, gibt es ein $\alpha\in\mathbb{K}, \alpha\not= 0$ mit:
\[\alpha \stackrel{(\mathbb{K}_2^2)}{=} \alpha \cdot 1 = \alpha \cdot 0 \stackrel{(2.1b)}{=} 0\]
Daher ist der Restklassenkörper modulo $2\ \mathbb{Z}_2$ der kleinste Körper.
\subsubsection{Beweis}
Wähle ein $\alpha ,\beta ,\gamma \in\mathbb{K}$. Es gilt $0\cdot \alpha \stackrel{(\mathbb{K}_1^2)}{=} (0+0)\cdot \alpha \stackrel{(\mathbb{K})}{=} 0\alpha + 0\alpha$ mittels Korollar 2.1.8 ($+,a=b=0$ und $c=0$) folgt $0\cdot \alpha = 0$, kommutativ liefert $\alpha 0 = 0$. Aus dieser Behauptung resultiert 
\[(-\beta )\alpha +\beta\alpha \stackrel{(\mathbb{K}_3)}{=} (-\beta + \beta)\alpha = 0\cdot \alpha = 0\]
mit Korollar 2.1.8 ($+,a=(-\beta )\alpha ,b=\beta\alpha$).  Dies liefert $-(\beta\alpha )=(-\beta )\alpha$ und $\beta (-\alpha )=-(\beta\alpha )$.  Die Beziehung $(-1)\alpha = -\alpha $ resultiert aus dem eben gezeigten $\beta = 1$ und 
\[(-1)\alpha = 1\cdot (-\alpha ) \stackrel{\mathbb{K}_2^2)}{=} -\alpha .\]
$2.1c$ ergibt sich mit Bemerkung $2.1.2(3)$ aus 
\[(-\alpha ) (-\beta )\stackrel{2.1b}{=}-(\alpha (-\beta )) \stackrel{2.1b}{=} -(-(\alpha\beta )) = \alpha\beta =0 \]
Annahme: $\alpha \not=0$ und $\beta\not=0$ dann $1\stackrel{\mathbb{K}_2^3)}{=}\frac{1}{\beta} \cdot \frac{1}{\alpha} \cdot \alpha\cdot\beta \stackrel{2.1b}{=} 0$
\subsection{Vektorräume}
\subsubsection{Definition (linearer Raum, Vektorraum)}
Es sei $\mathbb{K}$ ein Körper.  Ein Vektorraum oder linearer Raum $(X,+,\cdot )$ (über $\mathbb{K}$) ist eine nichtleere Menge $X$ mit arithmetische Operationen:
\begin{enumerate}
\item Addition $+:\ X\times X\rightarrow X$ derart, dass $(X,+)$ eine kommutative Gruppe mit neutralem Element $0$ oder Nullvektor.
\item Skalare Multiplikation $\cdot :\mathbb{K}\times X\rightarrow X$ derart, dass für alle $\alpha ,\beta \in \mathbb{K}$ und $x,y\in X$ gilt:
\begin{align*}
(V_1)&\ \alpha (x+y) = \alpha x+\alpha y \text{ Distributiv Gesetz}\\
(V_2)&\ (\alpha +\beta ) \cdot x = \alpha x + \beta x \text{ Distributiv Gesetz} \\
(V_3)&\ (\alpha\beta )\cdot x = \alpha \cdot (\beta \cdot x) \text{ Assoziativ Gesetz}\\
(V_4)&\ 1\cdot x = x
\end{align*}
Die Elemente aus $\mathbb{K}$ heißen Skalare und $X$ heißen Vektoren.
\end{enumerate}
Konventionen: $\alpha x := \alpha\cdot x$  $x-y:=x+(-y)$
\subsubsection{Beispiel}
Es sei ($\mathbb{K},+,\cdot $) ein Körper.\\
($0$) Der triviale Raum $\{0\}$ der nur die $0$ enthält.\\
($1$) Weiter ist $\mathbb{K}$ ein Vektorraum über sich selbst.\\
($2$) Die Menge aller $m\times n$-Matrizen $\mathbb{K}^{m\times n}$ ist ein linearer Raum über $\mathbb{K}$ bezüglich\\
($1.3b$) $\alpha A := \alpha A = (\alpha a_{i,j})_{\substack{1\leq i\leq m\\1\leq j\leq n}}$\\
($1.3c$) $A+B := (\alpha _{i,j}+\beta _{i,j})_{\substack{1\leq i\leq m\\1\leq j\leq n}}$\\
Ein $n$-Tupel ($x_1,\cdots ,x_n$)$\in \mathbb{K}^{1\times n}$ bezeichnen wir als Zeilenvektor und eine $m$-Spalte ($1.3a$) als Spaltenvektor.
\subsubsection{Beispiel}
Es sei $p\in\mathbb{N}$ eine Primzahl und $n\in\mathbb{N}$.  Dann sind die $n$-Spalten $\mathbb{Z}_p^n$ in $\mathbb{Z}_p$ mit den komponentenweisen Addition $+_p$ und skalaren Multiplikation $\cdot_p$ ein linearer Raum über $\mathbb{Z}_p$.\\
Insbesondere für $\mathbb{Z}_2^2$
\[\begin{array}{c|cccc}+_2 & \begin{pmatrix}0\\ 0\end{pmatrix} & \begin{pmatrix} 1 \\ 0 \end{pmatrix} & \begin{pmatrix}0 \\ 1\end{pmatrix} & \begin{pmatrix}1\\ 1\end{pmatrix} \\ \hline \\ \begin{pmatrix}
0\\ 0\end{pmatrix} &\begin{pmatrix}0 \\ 0\end{pmatrix} &\begin{pmatrix}1\\ 0\end{pmatrix} &\begin{pmatrix}0\\ 1\end{pmatrix} & \begin{pmatrix}1\\ 1\end{pmatrix} \\ \begin{pmatrix}
1\\ 0\end{pmatrix} &\begin{pmatrix}1 \\ 0\end{pmatrix} &\begin{pmatrix}0\\ 0\end{pmatrix} &\begin{pmatrix}1\\ 1\end{pmatrix} & \begin{pmatrix}0\\ 1\end{pmatrix} \\ \begin{pmatrix}
0\\ 1\end{pmatrix} & \begin{pmatrix}0 \\ 1\end{pmatrix} & \begin{pmatrix}1\\ 1\end{pmatrix} & \begin{pmatrix}0\\ 0\end{pmatrix} & \begin{pmatrix}1\\ 0 \end{pmatrix} \\ \begin{pmatrix}1\\ 1\end{pmatrix} & \begin{pmatrix}1 \\ 1\end{pmatrix} & \begin{pmatrix}0 \\ 1\end{pmatrix} & \begin{pmatrix}1\\ 0\end{pmatrix} & \begin{pmatrix}0\\ 0\end{pmatrix}\end{array} \]

\[\begin{array}{c|cccc}\cdot _2 & \begin{pmatrix}0\\ 0\end{pmatrix} & \begin{pmatrix} 1 \\ 0 \end{pmatrix} & \begin{pmatrix}0 \\ 1\end{pmatrix} & \begin{pmatrix}1\\ 1\end{pmatrix} \\ \hline \\ 0 &\begin{pmatrix}0 \\ 0\end{pmatrix} &\begin{pmatrix}0\\ 0\end{pmatrix} &\begin{pmatrix}0\\ 0\end{pmatrix} & \begin{pmatrix}0\\ 0\end{pmatrix} \\ 1 &\begin{pmatrix}0 \\ 0\end{pmatrix} &\begin{pmatrix}1\\ 0\end{pmatrix} &\begin{pmatrix}0\\ 1\end{pmatrix} & \begin{pmatrix}1\\ 1\end{pmatrix}\end{array}\]
\subsubsection{Beispiel (Lösungsmengen)}
Mit Satz $1.4.3$ ist $L_0$ einer homogenen Gleichung ein Vektorraum über $\mathbb{K}$.  Die Lösungsmenge $L_b$ inhomogener Systeme ist kein linearer Raum über $\mathbb{K}$.
\subsubsection{Beispiel (Funktionsräume)}
Es sei $\omega \not= \emptyset$ und $X$ ein linearer Raum über $\mathbb{K}$.  Dann ist $F(\omega ,X):=\{ u:\omega \rightarrow X\}$ ein Vektorraum über $\mathbb{K}$ mit punktweise definierten arithmetischen Operationen $(a+v)(t) := u(t)+v(t),\ (\alpha u)(t):= \alpha u(t)$ für alle $t\in\omega ,\alpha \in\mathbb{K}$.\\
Die Menge $F(\omega ,X)$ wird als Funktionenraum bezeichnet.  $\omega\in\mathbb{N},\ \omega\in\mathbb{Z}$, dann bezeichnen wir $F(\omega ,X)$ als Folgenraum.
\subsubsection{Korollar}
Ist $(X,+,\cdot )$ ein linearer Raum über $\mathbb{K}$ so gilt für alle Skalare $\alpha ,\beta \in\mathbb{K}$ und Vektoren $x,y\in X$:
\begin{align*}
(a)& 0_{\mathbb{K}} \cdot x = \alpha \cdot 0_x = 0_x\\
(b)& \text{Falls }\alpha x = 0_x\text{, so folgt } \alpha = 0\in\mathbb{K} \text{ oder } x\in 0 \in X \\
(c)& (-\alpha )x = \alpha (-\alpha )=-(\alpha x)\\
(d)& \alpha (x-y) = \alpha x - \alpha y \text{ und } (\alpha - \beta )x = \alpha x - \beta x
\end{align*}
Beweis: Es sei $\alpha \in \mathbb{K}$ und $x\in X$:
\renewcommand{\labelenumi}{(\alph{enumi})}
\begin{enumerate}
\item Es gilt $0_{\mathbb{K}} x = (0_{\mathbb{K}}+0_{\mathbb{K}})x = 0_{\mathbb{K}}x + 0_{\mathbb{K}}x$ wegen $V_2$. Nach Definition 2.2.1 (a) existiert zum Vektor $z:=0_{\mathbb{K}} x$ ein Vektor $-z$ mit $0\cdot x + (-z)=0_X$ und wir erhalten $0_X=0\cdot x + (-z) = (0\cdot x + 0\cdot x)+(-z) = 0\cdot x +(0\cdot x + (-z)) = 0\cdot x + 0_x = 0+x$ und die Beziehung $\alpha \cdot 0 = 0$ folge analog.
\item (b) Es gelte $\alpha x = 0$ mit $\alpha \neq 0$ und wir zeigen $x=0_x$ $\alpha \neq 0$ existiert $\frac{1}{\alpha}$. Nach (a) folgt ${\frac{1}{\alpha}} (\alpha \cdot x) = \frac{1}{\alpha} \cdot 0=0$ und andererseits $\frac{1}{\alpha} (\alpha x) = (\frac{1}{\alpha} \cdot \alpha) \cdot x=1\cdot x = x$
\item , (d)
\end{enumerate}
\subsubsection{Definition (Unterraum)}
Eine nicht leere Teilmenge $Y \subseteq X$ eines linearen Raumes $(X,+,\cdot)$ über $\mathbb{K}$ heißt Unterraum von X, falls gilt $\alpha_1 y_1 + \alpha_2 y_2 \in Y$ für alle $\alpha_1, \alpha_2\in\mathbb{K}$ und $y_1, y_2\in Y$
\subsubsection{Bemerkung}
Jeder lineare Raum x hat die trivialen Unterräume $\{0\}$ und X.
\subsubsection{Beispiel (Stetige und stetig-differenzierbare Funktion)}
Es sei $I\subseteq \mathbb{R}$ ein Inervall. Die Menge der stetigen Funktionen $C(I,\mathbb{R}^n)$ auf $I$ mit Bildern in $\mathbb{R}^n$ ist ein Unterraum von $F(I,\mathbb{R})$. Ebenso sind stetig differenzierbare Funktionen $C^1(I,\mathbb{R})$ ein Unterraum von $C(I,\mathbb{R})$ und $F(I,\mathbb{R}^n)$
\subsubsection{Beispiel (Polynome)}
Mit gegebenem Körper $\mathbb{K}$ definieren wir den Raum der Polynome (über $\mathbb{K}$) durch \\$P(\mathbb{K}) := \{p\in F(\mathbb{K},\mathbb{K}) \exists n\in\mathbb{N}_0: \exists a_0, ..., a_n \in \mathbb{K} : p(t)=\sum^{n}_{l=0} a_l \cdot t^l\}$;\\
seine Elemente heißen Polynome und die $a_k$ deren Koeffizienten. Dann ist $P(\mathbb{K})$ ein Unterraum von $F(\mathbb{K},\mathbb{K})$.\\
Der Grad $deg\ p$ eines Polynoms $p\in P(\mathbb{K})$ ist der maximale Inde $k\in\mathbb{N}_0$ für den $a_k=0$ ist. Für $m\in\mathbb{N}_0$ sind die Mengen $P_m(\mathbb{K}) := \{p\in P(\mathbb{K}):deg\ p \le m\}$

Unterräume von $P(\mathbb{K})$, wogegen $\{p\in P(\mathbb{K}): deg\ p =m\}$ für $m\neq 0$ kein Unterraum ist. Ferner ist jedes $P_n(\mathbb{K})$ Unterraum von $P_m(\mathbb{K})$ für $0\le n\le m$.
\subsubsection{Satz (Schnitte und Summen von Unterräumen)}
Ist $I$ eine nichtleere Indexmenge und und $(Y_i)_{i\in I}$ eine Familie von Unterräumen von X.
\begin{enumerate}
\item Der Durchschnitt $\displaystyle\bigcap_{i\in I} Y_i$ ist ein Unterraum von X.
\item Für endliche $I$ ist die Summe $\displaystyle\sum_{i\in I}Y_i := \{\sum_{i\in I} y_i\in X: y_i\in Y_i \text{ mit } i\in I\}$ der kleinste Unterraum von $X$, der jedes $y_i$ enthält.
\end{enumerate}
Für $I=\{1,...,n\}$ schreibt man auch $\displaystyle Y_1+...+Y_m=\sum_{i\in J} Y_i$.

Beweis:
\begin{enumerate}
\item Es seien $\alpha,p\in \mathbb{R}$ und $x,y\in \displaystyle\cap_{i\in I} Y_i$. Dann gilt $x,y \in Y_i$ für alle $i\in I$ und da jedes $Y_i$ ein Unterraum von X ist, folgt $\alpha\cdot x+\beta\cdot y \in Y_i$ für jedes $i\in I$. Dies impliziert, dass $\alpha\cdot x+\beta\cdot y \in \displaystyle\cap_{i\in I} Y_i$
\item Wir zeigen $\displaystyle Y := \sum_{i\in I} Y_i$ ist ein Unterraum von $X$. Dazu sei $\displaystyle x=\sum_{i\in I} x_i$ und $\displaystyle y=\sum_{i\in I} y_i$ mit $x_i,y_i\in Y_i$ und wir erhalten für alle $\alpha,\beta \in \mathbb{R}$:

$\displaystyle\alpha \cdot x+\beta\cdot y=\alpha\sum_{i\in I}x_i+\beta\sum_{i\in I} y_i=\sum_{i\in I}(\underbrace{\alpha x_i+\beta y_i}_{\in Y_i})$
\end{enumerate}
Zu zeigen $y$ ist kleinster Unterraum der alle $Y_i$ enthält.\\
Dazu sei $z\subseteq X$ ein weiterer Unterraum von $X$ der alle $Y_i$ enthält. Für $x_i\in Y_i$ ist dann auch $x_i\in Z$ für alle $i\in I$, da $Y_i$ in $Z$ enthalten sind.\\
Aus der Unterraumeigenschaft von $Z$ resultiert $\displaystyle\sum_{i\in I} x_i \in Z$ und folglich ist $Y\subseteq Z$
\subsection{Lineare Abhängigkeiten}
Gegeben sei eine nichtleere Menge $S$ von Vektoren aus einem linearen Raum X über dem Körper $\mathbb{K}$. Existieren zu einem gegebenem $x\in X$ dann endlich viele Koeffizienten $a_i\in\mathbb{R}$ und $x_i\in\mathcal{S}$, $1\leq i\leq n$, mit $\displaystyle x=\sum^{n}_{i=1} a_i \cdot x_i$  so bezeichnen wir $x$ als Linearkombination der Vektoren aus $S$.
\subsubsection{Definition (Spann)}
Es sei $\mathcal{S} \leq X$. Der Spann oder die lineare Hülle $span\ \mathcal{S}$ von $\mathcal{S}$ ist die Menge aller Linearkombinationen. Ferner setzt man $span\ \{0\}=\{0\}$.
\subsubsection{Beispiel}
Für endliche $\mathcal{S}=\{x_0,...,x_n\}$ ist der $\displaystyle span\ \mathcal{S}=\{\sum^n_{i=1} \alpha_i\cdot x_i\in X: \alpha_i \in \mathbb{K}\}$ $\mathbb{K}=\mathbb{R}$: $e_1=\begin{pmatrix}1\\0\end{pmatrix}$, $e_2=\begin{pmatrix}0\\1\end{pmatrix}$ gilt $span\ \{e_i,e_2\}=\mathbb{R}^2$\\
$span\ \{x_1,x_2\}$ wenn $x_1=\begin{pmatrix}1\\1\end{pmatrix}$ und $x_2=\begin{pmatrix}1\\-1\end{pmatrix}$ aber $y_1=\begin{pmatrix}1\\1\end{pmatrix}$ und $y_2=\begin{pmatrix}2\\2\end{pmatrix}$ dann $span\ \{y_1,y_2\} = \mathbb{R} \begin{pmatrix}1\\1\end{pmatrix} \in \mathbb{R}^2$ 
\subsubsection{Beispiel (Monome)}
Polynome $m_n(l):=t^n$, $n\in\mathbb{N}_0$ heißen Monome. Dann lassen sich die Polynome als lineare Hülle der Monome darstellen, d.h. $span\ \{m_n\}_{n\in\mathbb{N}_0}=P(\mathbb{K})$ insbesondere ist $span\ \{m_0,...,m_n\}=P_n(\mathbb{K}^n)$\\
$span\ \{m_{2n}\}_{n\in\mathbb{N}_0}=\{p\in P(\mathbb{K}):p(t)=p(-t) \text{ auf } \mathbb{K}\}$\\
$span\ \{m_{2n-1}\}_{n\in\mathbb{N}_0}=\{p\in P(\mathbb{K}):p(t)=-p(-t) \text{ auf } \mathbb{K}\}$
\subsubsection{Beispiel}
Es sei $\mathcal{S}\in X$ nicht leer. Dann ist die lineare Hülle der kleinste $\mathcal{S}$ umfassende Unterraum von $X$\\
\paragraph{Beweis:} $x,y\in \mathcal{S}$ ist $\alpha x+\beta y$, $\alpha,\beta\in\mathbb{K}$ in $span\ \mathcal{S}$. Also ist $span\ \mathcal{S}$ Unterraum von $X$. $span\ \mathcal{S}$ enthält die Vektoren aus $\mathcal{S}$ und damit ist $\mathcal{S}\subseteq span\ \mathcal{S}$, $Y\subseteq X$ ein Unterraum von $X$ mit $x\in Y$ für sämtliche $x\in\mathcal{S}$. Dann liegen sämtliche Linearkombinationen von Vektoren aus $\mathcal{S}$ in $Y$. Also ist $span\ \mathcal{S}$ in $Y$ enthalten.
\subsubsection{Korollar}
Ist $x$ eine Linearkombination von Vektoren aus $\mathcal{S}\subseteq X$, so gilt span$\mathcal{S}$=span($\mathcal{S}\cup \{x\}$).\\
\underline{Beweis}: Wir zeigen die Behauptung durch zwei Inklusionen:\\
$(\subseteq )$ Es ist klar dass span$\mathcal{S}\subseteq$span($\mathcal{S}\cup\{x\}$)\\
$(\supseteq )$ Also Linearkombination von Vektoren aus $\mathcal{S}$ liegt $x$ auch in span$\mathcal{S}$.\\
Demnach ist span$\mathcal{S}$ derjenige Unterraum welcher $\mathcal{S}$ und $\{x\}$ enthält.\\
Damit folgt aus Prop 2.3.4, dass span($\mathcal{S}\cup\{x\}$)=span$\mathcal{S}$.
\subsubsection{Definition (lineare Unabhängigkeit)}
Eine endliche Menge $\{x_1,\cdots ,x_n\}$ von Vektoren aus $X$ heißt linear unabhängig falls gilt:
\[\sum^n_{k=1} \xi _k x_k = 0 \Rightarrow \xi _k =0 \forall n=1,n\]
Griechische Buchstaben:
\[\eta \ - \text{ eta}\]
\[\xi \ - \text{ xi}\]
\[\zeta \ - \text{ zeta} \]
Für beliebige Mengen $\mathcal{S}\subseteq X$ nennt man $\mathcal{S}$ linear unabhängig, wenn jede endliche Teilmenge von $\mathcal{S}$ linear unabhängig ist, die leere Menge $\emptyset$ wird als lineare unabhängig betrachtet.  Eine Teilmenge von $X$ heißt linear abhängig, falls sie nicht linear unabhängig ist.\\
Man nennt Vektoren $x_1 ,x_2 ,\cdots $ linear unabhängig, wenn $\{x_1,x_2,\cdots \}$ diese Eigenschaft hat.
\subsubsection{Bemerkung}
\renewcommand{\labelenumi}{(\arabic{enumi})}
\begin{enumerate}
\item lineare Abhängigkeit einer endlichen Menge $\{x_1,\cdots x_n\}$ bedeutet, dass eine nichttriviale Darstellung der Null aus Vektoren $x_u$ existiert:\\
Man Kann also
\[(2.3a) \sum_{k=1}^n \xi _kx_k = 0\]
schreiben, ohne dass alle $\xi _k$ verschwinden.
\item Jede Obermenge einer linear abhängigen Menge ist linear abhängig.  Jede Teilmenge einer linear unabhängigen Menge ist linear unabhängig.
\end{enumerate}
\subsubsection{Beispiel}
Die Menge $\{0\}$ ist linear abhängig, dagegen ist $\{x\},x\not= 0$, linear unabhängig.
\subsubsection{Proposition}
Es sei $\mathcal{S}\subseteq X$ nichtleer und $x,x_1,\cdots ,x_n \in X$
\renewcommand{\labelenumi}{(\alph{enumi})}
\begin{enumerate}
\item Ist $\mathcal{S}=\{x_1, \cdots ,x_n\}$ linear abhängig, so lässt sich mindestens ein Vektor aus $\mathcal{S}$ als Linearkombination der weiteren Elementen von $\mathcal{S}$ darstellen.
\item Für jede Linearkombination $x$ aus $\mathcal{S}$ ist $\mathcal{S}\cup \{x\}$ linear abhängig.
\end{enumerate}
\underline{Beweis}:
\begin{enumerate}
\item Weil $\{x_1,\cdots ,x_n\}$ linear abhängig ist, besitzt $0$ die Darstellung ($2.3a$) in welcher nicht alle $\xi _k$ verschwinden.  Also existiert ein Index $1\leq k^*\leq n$ mit $\xi _{k^*} \not= 0$ und damit
\[X_{k^*} = -\xi _k^{-1} \sum_{\substack{k=1\\ k\not=k^*}}^n \xi _k x_k =\sum_{\substack{k=1\\ k\not=k^*}}^n (-\xi _k^{-1} \xi _k) x_k\]
\item Mit $x=\sum_{k=1}^n\xi _k x_k$ ist $x - \sum_{k=1}^n \xi _k x_k$ eine nichttriviale Darstellung der $0$
\end{enumerate}
In $X=\mathbb{K}^m$ gilt: Es sei $\mathcal{S}=\{a_1,\cdots ,a_n\}\subseteq \mathbb{K}^m$.  Mit der $m\times n$-Matrize $A:= (a_1,\cdots ,a_n)$ ist die Beziehung $\sum^n_{k=1} \xi _k a_k =0$ (vgl. ($2.3a$)) äquivalent zu:
\[ (2.3b) Ax=0, x\begin{pmatrix}\xi _1 \\ \vdots \\ \xi_n\end{pmatrix}\]
Demzufolge ist $\mathcal{S}$ genau dann linear unabhängig, wenn $Ax=0$ nur die triviale Lösung hat.  Aus Satz 1.4.8 (in Verbindung mit Blatt 5, Aufg. 1) erhalten wir daher, dass mehr als $m$ Vektoren stets linear abhängig sind.
\subsubsection{Beispiel}
\renewcommand{\labelenumi}{(\arabic{enumi})}
\begin{enumerate}
\item Für die \underline{kanonischen Einheitsvektoren} in $\mathbb{K}^m$
\[ e_1=\begin{pmatrix}1\\ 0 \\ \vdots \\ 0\end{pmatrix},e_2=\begin{pmatrix}0\\ 1 \\ \vdots \\ 0\end{pmatrix}, \cdots e_m=\begin{pmatrix}0 \\ 0 \\ \vdots \\ 1\end{pmatrix}\]
gilt in obiger Terminologie $A=I_m$.  Also besitzt $Ax=0$ nur die triviale Lösung und $\{e_1,\cdots ,e_m\}$ ist linear unabhängig.
\item Es sei $\lambda \in \mathbb{R}$ um die lineare Unabhängigkeit von 
\[x_1\begin{pmatrix}1\\ 2\\ 3\end{pmatrix}, x_2=\begin{pmatrix}4\\ 5\\ 6\end{pmatrix}, x_3=\begin{pmatrix}7\\ 8\\ \lambda \end{pmatrix}\]
in $\mathbb{R}^3$ zu untersuchen, betrachten wir die Gleichung $(2.3b)$ mit
\[A=\begin{pmatrix}1 & 4 & 7\\2 & 5 & 8\\ 3 & 6 & \lambda\end{pmatrix}\]
und lösen sie mit dem in Beispiel 1.4.6 beschriebenen Schema:
\[\begin{array}{ccc|c}1 & 4 & 7 & 0\\ 2 & 5 & 6 & 0\\ 3 & 6 & \lambda \end{array}\begin{matrix}\\ 2I-II\\ 3I-II\end{matrix} \Rightarrow \begin{array}{ccc|c}1 & 4 & 7 & 0\\ 0 & 3 & 6 & 0\\ 0 & 6 & 21 - \lambda \end{array}\begin{matrix}\\ :3\\ III-2II\end{matrix} \Leftrightarrow \begin{array}{ccc|c}1 & 4 & 7 & 0\\ 0 & 1 & 2 & 0\\ 0 & 0 & 9 - \lambda \end{array}\begin{matrix}\\ :3\\ III-2II\end{matrix}\]
Also hat $Ax=0$ für $\lambda \not= 9$ nur die triviale Lösung (lineare Unabhängigkeit von $\{x_1,x_2,x_3\}$ und für $\lambda = 9$ nichttriviale Lösungen (lineare Abhängigkeit).
\end{enumerate}
\subsubsection{Satz}
Eine Menge $\mathcal{S}\subseteq X$ ist genau dann linear unabhängig, wenn jedes $x\in\mathcal{S}$ auf nur eine Art (bis auf Glieder mit Null-Koeffizienten) als Linearkombinationen von Vektoren aus $\mathcal{S}$ dargestellt werden kann.
\subsection{Basis und Dimensionen}
Es sei $X$ ein linearer Raum über den Körper $\mathbb{K}$.
\subsubsection{Definition (Basis)}
Eine Menge $\mathcal{X}\subseteq X$ heißt \underline{Basis} von X, falls $\mathcal{X}$ linear unabhängig mit $X=$span$\mathcal{X}$ ist:\\
Eine Menge $\mathcal{X}$ mit $X=$span$\mathcal{X}$ heißt Erzeugendessystem (EZS) von $X$ genannt.  Man nennt $X$ endlich erzeugt, falls er ein endliches EZS hat.
\subsubsection{Beispiel}
Die Basis von $\{0\}$ ist die leere Menge.
\subsubsection{Beispiel (Standardbasis)}
Die mittels der kanonischen Einheitsvektoren aus Beispiel 2.3.10 (1) gebildete Menge $\mathcal{E}_m:=\{e_1,\cdots ,e_m\}$ ist eine Basis von $\mathbb{K}^m$, die sogenannte Standardbasis, damit ist $\mathbb{K}^m$ endlich erzeugt.
\subsubsection{Beispiel (Polynome)}
Für $\mathbb{K}=\mathbb{R}$ oder $\mathbb{K}=\mathbb{C}$ sind $\mathcal{M}_n:=\{m_0,\cdots m_n\}$ aus Beispiel 2.3.3 eine Basis der Polynome $\mathcal{P}_n(\mathbb{K})$ von maximalem Grad $n$.  Ebenso ist $\{m_n\}_{n\in\mathbb{N}_0}$ eine Basis von $\mathcal{P}(\mathbb{K})$.  Somit ist jedes $\mathcal{P}_n(\mathbb{K})$ endlich erzeugt, $\mathcal{P}(\mathbb{K})$ dagegen nicht.
\subsubsection{Lemma}
Es sei $\mathcal{S}\subseteq X$ linear unabhängig.  Gilt dann $x\not\in$span$\mathcal{S}$, so ist auch $\mathcal{S}\cup\{x\}$ linear unabhängig. \\
\underline{Beweis}:  Es ist nachzuweisen, dass jede endliche Teilmenge von $\mathcal{S}\cup\{x\}$ linear unabhängig ist.  Dazu sei $\{x_1,\cdots x_n,x\}$ eine solche Menge und $\sum_{k=1}^n \xi _k x_k +\eta x=0$ eine Darstellung der Null.  Wäre $\eta \not= 0$, so könnte man $x$ als Linearkombination der $x_1,\cdots ,x_n$ darstellen, dies widerspricht $x\not\in$span$\mathcal{S}$.  Also gilt $\eta = 0$.  Da aber $\{x_1,\cdots ,x_n\}$ linear unabhängig ist, folgt $\xi _1 = \cdots = \xi _n = 0$.  In trivialer Weise: ist $X$ ein EZS von $X$.  Unser Interesse besteht aber gerade in "`kleinen"' EZSen.
\subsubsection{Satz}
Mit nicht leerem $\mathcal{X}\subseteq X$ sind äquivalent:
\renewcommand{\labelenumi}{(\alph{enumi})}
\begin{enumerate}
\item $\mathcal{X}$ ist eine Basis von $X$
\item Jeder Vektor $x\in X$ lässt sich eindeutig als Linearkombination von Vektoren aus $\mathcal{X}$ darstellen.
\item $\mathcal{X}$ ist \underline{maximal linear unabhängig}, d.h. $\mathcal{X}$ ist linear unabhängig und für jedes $x\in X\setminus \mathcal{X}$ ist $\mathcal{X}\cup\{x\}$ linear abhängig.
\item $\mathcal{X}$ ist ein \underline{minimales EZS}, d.h. keine echte Teilmenge von $\mathcal{X}$ ist ein EZS.
\end{enumerate}
\subsubsection{Bemerkung (Koordinaten)}
Besitzt $x\in X$ bzgl. der Basis $\mathcal{X}:=\{x_1,\cdots ,x_n\}$ die nach Satz 2.4.6 (b) eindeutige Darstellung $x=\sum_{k=1}^n \xi _k x_k$ mit Koeffizienten $\xi _k \in \mathbb{K}$ so bezeichnet man das $n$-tupel ($\xi _1,\cdots ,\xi _n$) also \underline{Koordinaten} von $x$ (bzgl. $\mathcal{X}$).  Von nun an sei $X$ endlich erzeugt.
\subsubsection{Satz}
Jedes endliche EZS eines Vektorraumes enthält eine Basis.  Insbesondere hat jeder endlich erzeugte lineare Raum eine Basis.\\
\underline{Beweis}:
Es sei $\mathcal{X}$ ein endliches EZS.  Ist $\mathcal{X}$ keine Basis, so kann $\mathcal{X}$ nicht minimal sein und es existiert eine echte Teilmenge $\mathcal{X}^1 \stackrel{\subset}{\not=} \mathcal{X}$, die ebenfalls ein EZS ist.  Ist wiederum $\mathcal{X}^1$ keine Basis, so existiert erneut eine echte Teilmenge $\mathcal{X}^2 \stackrel{\subset}{\not=} \mathcal{X}^1$, die $X$ erzeugt.  Durch Iteration erhält man eine echt absteigende Folge von Teilmengen $\cdots \subsetneqq \mathcal{X}^2 \subsetneqq \mathcal{X}^1 \subsetneqq \mathcal{X}$.  Diese Folge bricht nach endlich vielen schritten ab, da $\mathcal{X}$ endlich ist, d.h. es gibt ein minimales $\mathcal{X}^k$.  Dieses $\mathcal{X}^k$ ist nach Satz 2.4.6 eine Basis von $X$.
\subsubsection{Proposition}
Ist $X$ endlich erzeugbar und $\mathcal{S}\subseteq X$ linear unabhängig, so existiert eine Basis von $X$, welche $\mathcal{S}$ als Teilmenge enthält.
\subsubsection{Lemma (Austauschsatz von Steinitz)}
Ist $\{x_1,\cdots x_p\}$ linear unabhängig und $\{y_1,\cdots ,y_n\}$ ein EZS von $X$, so gilt $p\leq n$ und nach einer Umnummerierung der $y_k$ ist $\{x_1,\cdots ,x_p,y_{p+1},\cdots ,y_n\}$ ein EZS von $X$.
\subsubsection{Satz (Dimension)}
Falls $X$ eine Basis von $n$ Elementen besitzt, enthält jede Basis von $X$ genau $n$ Elemente.  Wir bezeichnen $n$ als \underline{Dimension} von $X$ und schreiben $n=$dim$X$.
\subsubsection{Bemerkung}
Ein linearer Raum $X$ heißt \underline{unendlich-dimensional} (symbolisch dim$X=\infty$) falls er kein endlichen EZS besitzt, anderenfalls heißt er endlich-dimensional.\\
\underline{Beweis}: Es seien $\{x_1,\cdots ,x_n\}$ und auch $\{y_1,\cdots ,y_m\}$ Basen von $X$.  Mit Lemma 2.4.10 folgt dann $n\leq m$, wie auch $m\leq n$, und somit $m=n$.
\subsubsection{Beispiel}
Für die bislang betrachteten Räume ist dim$\mathbb{K}^n=n$, dim$\mathbb{K}^{m\times n}=m\cdot n$, dim$\mathcal{P}_n(\mathbb{R})=n+1$ und dim$\mathcal{P}(\mathbb{R})=$dim$C^1(\mathbb{R},\mathbb{R})=$dim$C(\mathbb{R},\mathbb{R})=$dim$F(\mathbb{R},\mathbb{R})=\infty$.
\subsubsection{Beispiel}
Die komplexen Zahlen $\mathbb{C}$ sind ein 2-dimensionaler Vektorraum über $\mathbb{R}$ und ein 1-dimensionaler Raum über $\mathbb{C}$.
\subsubsection{Korollar}
In linearen Räumen $X$ mit $n:=$dim$X$ gilt:
\begin{enumerate}
\item Weniger als $n$ Vektoren aus $X$ sind kein EZS.
\item Mehr als $n$ Vektoren aus $X$ sind linear abhängig.
\item Jedes EZS mit $n$ Elementen ist eine Basis.
\item Jede linear unabhängige Menge mit $n$ Elementen ist eine Basis.
\end{enumerate}
\underline{Beweis}: 
\begin{enumerate}
\item jedes EZS enthält laut Satz 2.4.8 eine Basis.  Für jedes aus weniger als $n$ Vektoren bestehenden EZS gäbe es dann auch eine Basis mit Weniger als $n$ Elementen.  Dies widerspricht Satz 2.4.11.
\item Laut Proposition 2.4.9 ist jede linear unabhängige Menge Teil einer Basis.  Somit hätte man mit einer linear unabhängigen Familie von mehr als $n$ Vektoren auch eine Basis mit mehr als $n$ Elementen - im Widerspruch zu 2.4.11.
\item Ein EZS enthält wegen Satz 2.4.8 eine Basis und ist wegen Satz 2.4.11 bereits eine solche.
\item Mit Proposition 2.4.9 ist eine linear unabhängige Familie Teilmenge einer Basis und mit Satz 2.4.11 eine Basis.
\end{enumerate}
\subsubsection{Korollar}
Für jeden Unterraum $Y$ eines endlich-dimensionalen Raumes $X$ ist dim$Y\leq$dim$X$, Gleichheit gilt genau für $X=Y$.
\subsection{Komplemente und direkte Summen}
\subsubsection{Definition (direkte Summen)}
\subsubsection{Beispiel} 
\subsubsection{Beispiel}
Wir betrachten den Unterraum $Y_n:=\{p\in P(\mathbb{K})\}:p(0)=0\}$ von $X=P(\mathbb{K})$.  Dann gilt $P(\mathbb{K})=Y_1 \oplus P_0(\mathbb{K})$, d.h. der lineare Raum aller konstanten Polynome ist ein Komplement von $Y_1$.
\subsubsection{Satz}
Es seien $Y_1,Y_2\subseteq X$ Unterräume.  Es ist $X=Y_1\oplus Y_2$ genau dann, wenn es zu jedem $x\in X$ eindeutige $y_1\in Y_1,y_2\in Y_2$ mit $x=y_1+y_2$ gilt.\\
\underline{Beweis}:\\
($\Rightarrow$) Es sei $Y_2$ ein Komplement von $Y_1$ und $X$.  Wegen $Y_1+Y_2=X$ lässt sich jedes $x\in X$ darstellen als $x=y_1+y_2$ mit $y_1\in Y_1,y_2\in Y_2$.  Um deren Eindeutigkeit zu verifizieren, sein $\hat{y}_1\in Y_1,\hat{y}_2\in X_2$ zwei weitere Vektoren mit $x=\hat{y}_1+\hat{y}_2$.  Dies impliziert $y_1-\hat{y}_2=\hat{y}_2-y_2$ und $y_1-\hat{y}_1\in Y_1$ für $i=1,2$ und folglich $y_i-\hat{y}_i\in Y_1\cap Y_2$ für $i=1,2$.  Wegen $Y_1\cap Y_2 = \{0\}$ folgt $y_1=\hat{y}_1$ und $y_2=\hat{y}_2$.\\
\\
($\Leftarrow$) Umgekehrt seien $Y_1,Y_2\subseteq X$ Unterräume derart, dass sich jedes $x\in X$ eindeutig als Summe $X=y_1+y_2$ mit $y_i\in Y_i,i=1,2$, darstellen lässt.  Dann gilt sicherlich $Y_1+Y_2=X$.  Ist nun $x\in Y_1\cap Y_2$, so gilt $x=x+0=0+x$ und da die Darstellung eindeutig sein muss, resultiert $x=0;$ also $Y_1\cap Y_2=\{0\}$.
\subsubsection{Satz}
Jeder Unterraum eines endlich dimensionaler linearer Raumes hat ein Komplement.\\
\underline{Beweis}(-skizze):\\
Ergänze eine Basis von $Y_1$ zu einer Basis von $X$ gemäß Proposition 2.4.9.
\subsection{Anwendung: Matrizen und lineare Gleichungen}
Es sei $\mathbb{K}$ ein Körper und $A\in\mathbb{K}^{m\times n}$ mit den $n$ Spalten und den $m$ Zeilen.  Die $n$ Spalten seien $a_1,\cdots ,a_n\in \mathbb{K}^m$ und $a^1,\cdots ,a^m\in \mathbb{K}^{1\times n}$ die Zeilen von $A$.  Man bezeichnet den Unterraum span$\{a_k\}_{1\leq k\leq n}\subseteq \mathbb{K}^m$ als Spaltenraum und span$\{a^1,\cdots ,a^m\}\subseteq \mathbb{K}^{1\times n}$ als \underline{Zeilenraum} von $A$.
\[A=\begin{pmatrix}a^1\\ \vdots \\ a^m\end{pmatrix} = (a_1,\cdots ,a_n)\]
\subsubsection{Definition (Rang einer Matrix)}
Der \underline{Rang} (rk$A$) einer Matrix $A\in\mathbb{K}^{m\times n}$ ist die Dimension ihres Zeilenraumes.
\subsubsection{Bemerkung}
$0\leq$rk$A\leq m$
\[(L_0) Ax=0\]
\subsubsection{Proposition}
Der Lösungsraum $L_0\subseteq\mathbb{K}^n$ von ($L_0$) erfüllt dim$L_0=n-$rk$A$.\\
\underline{Beweis}:\\
Wir können o.B.d.A (ohne Beschränkung der Allgemeinheit) annehmen, dass $A\in\mathbb{K}^{m\times n}$ in strenger Zeilen-Stufen-Form ist.  Es sei $r$ die Anzahl der Zeilen von $A$, welche mindestens ein Element $\not=\ 0$ besitzen - dies ist der Rang von $A$.  Für $1\leq i\leq r$ sei $j_i$ derjenige Spaltenindex, in welcher das erste Element $\not=\ 0$ der $i$-ten Zeile steht.  Weiter seien $k_1,\cdots ,k_{n-r}$ diejenigen Element von $\{1,\cdots ,n\}$, welche nicht in $\{j_1,\cdots ,j_r\}$ sind.  Dann gilt 
\[L_0=\left\{x=\begin{pmatrix}\xi _1\\ \vdots \\ \xi_n\end{pmatrix}\in\mathbb{K}^n:\xi _1,\cdots ,\xi _{k_{n-r}} \in\mathbb{K}\ \mathrm{und}\ \xi _{j_i}=-\frac{1}{a_{i,j_i}}\sum_{j=1}^{n-r} a_{i,k_j} \xi _{k_j}\text{ für }1\leq i\leq r\right\}\]
und $x_1,\cdots x_{n-r}\in\mathbb{K}^n$ bezeichne die Vektoren in $L_0$ mit $\xi _{k_j}=1$ und $\xi _{k_i}=0$ für $i\not= j$.  Man überlegt sich nun, dass $\{x_1,\cdots x_{n-r}\}$ eine Basis von $L_0$ und die Behauptung folgt.